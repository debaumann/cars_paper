Training Epoch 1/30:   0%|                                            | 0/3100 [00:01<?, ?it/s]
torch.Size([8, 1, 3, 496, 496])
Traceback (most recent call last):
  File "/cluster/home/debaumann/cars_paper/attention_vit.py", line 256, in <module>
    main()
  File "/cluster/home/debaumann/cars_paper/attention_vit.py", line 95, in main
    logits,hand,obj = model(pixel_values)
                      ^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/miniconda3/envs/transformer/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/miniconda3/envs/transformer/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/cars_paper/utils/vit_train_utils.py", line 166, in forward
    outputs = self.vit_model(pixel_values, output_attentions=True, interpolate_pos_encoding=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/miniconda3/envs/transformer/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/miniconda3/envs/transformer/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/miniconda3/envs/transformer/lib/python3.11/site-packages/transformers/models/vit/modeling_vit.py", line 570, in forward
    embedding_output = self.embeddings(
                       ^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/miniconda3/envs/transformer/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/miniconda3/envs/transformer/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/debaumann/miniconda3/envs/transformer/lib/python3.11/site-packages/transformers/models/vit/modeling_vit.py", line 118, in forward
    batch_size, num_channels, height, width = pixel_values.shape
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: too many values to unpack (expected 4)
